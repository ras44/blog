y = c(1, 1, 0, 0, -1, -1)
x = c(0, persuadables/N, persuadables/N, 1-dogs/N, 1-dogs/N, 1)
list(x=x, y=y)
}
maximal_cuplift_curve <- function(func, Nt1o1, Nt0o1, Nt1o0, Nt0o0){
counts = get_tc_counts(Nt1o1, Nt0o1, Nt1o0, Nt0o0)
Nt1 = counts$Nt1
Nt0 = counts$Nt0
N = counts$N
pdsl = func(Nt1o1, Nt0o1, Nt1o0, Nt0o0)
persuadables = pdsl$persuadables
dogs = pdsl$dogs
sure_things = pdsl$sure_things
lost_causes = pdsl$lost_causes
kink_y = (persuadables[2] + sure_things[2])/(persuadables[2] + sure_things[2] + lost_causes[2])
- (sure_things[1])/(persuadables[1] + sure_things[1] + lost_causes[1])
y = c(1, 1, kink_y, (Nt1o1/Nt1-Nt0o1/Nt0))
x = c(0, sum(persuadables)/N, 1-sum(dogs)/N, 1)
list(x=x, y=y)
}
get_scores <- function(treatment, outcome, prediction, p, scoring_range=c(0,1), plot_type='all'){
counts = get_counts(treatment, outcome, p)
Nt1o1 = counts$Nt1o1
Nt0o1 = counts$Nt0o1
Nt1o0 = counts$Nt1o0
Nt0o0 = counts$Nt0o0
counts = get_tc_counts(Nt1o1, Nt0o1, Nt1o0, Nt0o0)
Nt1 = counts$Nt1
Nt0 = counts$Nt0
N = counts$N
riemann <- function(xy){
x <- xy$x
y <- xy$y
stopifnot(length(x)==length(y))
xi <- utils::head(x, length(x)-1)
xip1 <- utils::tail(x,length(x)-1)
yi <- utils::head(y,length(y)-1)
yip1 <- utils::tail(y, length(y)-1)
avgy <- (yi+yip1)/2
dx <- (xip1-xi)
sum(avgy*dx)
}
qini_riemann = riemann(maximal_qini_curve(get_overfit_counts, Nt1o1, Nt0o1, Nt1o0, Nt0o0))
practical_qini_riemann = riemann(maximal_qini_curve(get_no_sure_thing_counts, Nt1o1, Nt0o1, Nt1o0, Nt0o0))
overall_lift = (Nt1o1/Nt1-Nt0o1/Nt0)
qini_max = qini_riemann - 0.5*overall_lift
practical_qini_max = practical_qini_riemann - 0.5*overall_lift
# The predicted Qini curve.
# First we need to reorder the y values and y_pred based on this reordering
# We calculate TOT roughly here so we have a way of distinguishing those that (ordered, treated) and those that (ordered, untreated).
y = (2*treatment - 1)*outcome
sortbyprediction <- function(vec){
vec[order(prediction,decreasing = TRUE)]
}
y_ordered = sortbyprediction(y)
tr_ordered = sortbyprediction(treatment)
p_ordered = sortbyprediction(p)
auc <- function(method='qini'){
# Calculate the area.
uplift_last = 0
nt1o1 = 0
nt0o1 = 0
nt1 = EPS
nt0 = EPS
pred_riemann = 0
uplifts = c()
for(i in seq(round(scoring_range[1]*length(treatment))+1, round(scoring_range[2]*length(treatment)))){
if(y_ordered[i] > 0){
nt1o1 = nt1o1 + 0.5*(1/p_ordered[i])
} else if (y_ordered[i] < 0){
nt0o1 = nt0o1 + 0.5*(1/(1-p_ordered[i]))
}
if (tr_ordered[i] == 1){
nt1 = nt1 + 0.5*(1/p_ordered[i])
}
else{
nt0 = nt0 + 0.5*(1/(1-p_ordered[i]))
}
if(method=='qini'){
uplift_next = nt1o1/Nt1-nt0o1/Nt0
} else if (method=='cgains'){
uplift_next = (nt1o1/nt1-nt0o1/nt0)*(nt1+nt0)/N
} else if (method=='aqini'){
uplift_next = nt1o1/Nt1-nt0o1*nt1/(nt0*Nt1 + EPS)
}
uplifts = c(uplifts, uplift_next)
# each point corresponds to an x delta of 1/N
pred_riemann = pred_riemann + 1/2*(uplift_next+uplift_last)/N
uplift_last = uplift_next
}
AUC = pred_riemann - 0.5*overall_lift*(scoring_range[2]**2 - scoring_range[1]**2)
maxgain = max(uplifts)
list(
AUC = AUC,
maxgain = maxgain)
}
# Dictionary to store all scores.
scores = list()
# Raw max scores.
scores$Q_max = qini_max
scores$overall_lift = overall_lift
scores$Q_practical_max = practical_qini_max
if ((plot_type=='qini') | (plot_type=='all')){
# Qini curve scores.
auc = auc(method='qini')
scores$Q_qini = auc$AUC
scores$max_qini = auc$maxgain
scores$q1_qini = scores$Q_qini/scores$Q_max
scores$q2_qini = scores$Q_qini/scores$Q_practical_max
} else if ((plot_type=='cgains') | (plot_type=='all')){
# Scores for cumulative gains curve.
auc = auc(method='cgains')
scores$Q_cgains = auc$AUC
scores$max_cgains = auc$maxgain
scores$q1_cgains = scores$Q_cgains/scores$Q_max
scores$q2_cgains = scores$Q_cgains/scores$Q_practical_max
} else if ((plot_type=='aqini') | (plot_type=='all')){
# Scores for adjusted qini curve.
auc = auc(method='aqini')
scores$Q_aqini = auc$AUC
scores$max_aqini = auc$maxgain
scores$q1_aqini = scores$Q_aqini/scores$Q_max
scores$q2_aqini = scores$Q_aqini/scores$Q_practical_max
}
scores
}
pl_plot(plUpliftEval(W.test, Y.test, tau.hat$predictions),
show_practical_max = TRUE,
show_theoretical_max = TRUE,
show_no_dogs = TRUE,
n_bins=20)
library(uplifteval)
set.seed(123)
alpha <- 0.1
n <- 1000
W <- rbinom(n, 1, 0.5)
Y <- W
p1 <- Y + alpha*rnorm(n)
plot_uplift_guelman(p1, W, Y, groups=10)
library(grf)
rl <- function(x){
round(1/(1+exp(-x)))
}
n = 2000; p = 10
X = matrix(rnorm(n*p), n, p)
W = rbinom(n, 1, 0.2)
Y = rl(rl(X[,1]) * W - rl(X[,3]) * W + rnorm(n))
tau.forest = causal_forest(X, Y, W)
tau.hat = predict(tau.forest, X)
plot_uplift_guelman(tau.hat$predictions, W, Y)
library(tweedie)
#
# Case: plot_uplift_guelman fails to find quantiles
#
# Generate equal prediction distributions
n <- 1000
W <- rbinom(n, 1, 0.5)
Y <- rbinom(n, 1, 0.5)
p1 <- rtweedie(n, xi=1.4, mu=1, phi=1)
hist(p1,100)
plot_uplift_guelman(p1, W, Y, groups=10)
library(grf)
library(ggplot2)
library(uplifteval)
# Utility function round logistic function maps R -> {0,1}
rl <- function(x){
round(1/(1+exp(-x)))
}
# Generate feature data
set.seed(123)
n = 2000; p = 10
X = matrix(rnorm(n*p), n, p)
X.test = matrix(rnorm(n*p), n, p)
library(grf)
library(ggplot2)
library(uplifteval)
#
# Case 1: randomized control trial, treatment propensity is feature independent and equal
# for treatment and control cases, 50-50
#
# Treatment/Response Train/Test
set.seed(123)
W = rbinom(n, 1, 0.5)
W.test = rbinom(n, 1, 0.5)
Y = rl(rl(X[,1]) * W - rl(X[,3]) * W + rnorm(n))
Y.test = rl(rl(X.test[,1]) * W.test - rl(X.test[,3]) * W.test + rnorm(n))
tau.forest = causal_forest(X, Y, W)
tau.hat = predict(tau.forest, X.test)
plot_uplift(tau.hat$predictions, W.test, Y.test)
#' Creates an uplift plot of cumulative differential treatment/control outcomes
#' versus model score.  Also provides a selection of metrics: max uplift as pct
#' of total control outcome, optimum users targeted and optimum score targeting
#' range.
#'
#' @param p1 numeric vector of uplift predictions; can also be predicted outcomes
#'   for treated case (in this case p0 should contain predicted outcomes for
#'   the control case)
#' @param W binary vector {1,0} of treatment assignments
#' @param Y numeric vector of responses
#' @param ns integer number of samples per bootstrap iteration; default min(table(W))
#' @param n_bs integer number of bootstrap iterations
#' @param W_label optional labels for the treatment options (default W)
#' @param p0 optional numeric vector of predicted outcomes for control case
#' @param balanced optional boolean whether to sample equal proportions from
#'   treatment and control cases; default TRUE
#' @param replace optional boolean whether to use replacement when sampling;
#'   default TRUE
#' @param x_interval optional numeric the interval with which to split the
#' @param ... additional arguments (unused)
#'   x-axis
#'
#' @import ggplot2 graphics
#' @importFrom dplyr %>%
#'
#' @examples \dontrun{
#'
#' set.seed(123)
#'
#' rl <- function(x){
#'   round(1/(1+exp(-x)))
#' }
#' n = 2000; p = 10
#' X = matrix(rnorm(n*p), n, p)
#' W = rbinom(n, 1, 0.2)
#' Y = rl(rl(X[,1]) * W - rl(X[,3]) * W + rnorm(n))
#' tau.forest = causal_forest(X, Y, W)
#' tau.hat = predict(tau.forest, X)
#' plot_uplift(tau.hat$predictions, W, Y, n_bs=20, x_interval = 0.05, balanced = FALSE)
#' plot_uplift(tau.hat$predictions, W, Y, n_bs=20, x_interval = 0.05, balanced = TRUE)
#'
#' }
#' @export
plot_uplift <- function(p1,
W,
Y,
ns=min(table(W)),
n_bs = 1,
W_label=W,
p0=rep(0,length(p1)),
balanced = TRUE,
replace = TRUE,
x_interval = 0.1,
...
){
q_pred_t <- c()
q_pred_c <- c()
q_resp <- c()
q_treat <- c()
q_treat_label <- c()
q_iter <- c()
if(balanced){
for(i in c(1:n_bs)){
inds_t0 <- sample(seq_along(W)[W==0],ns, replace = replace)
inds_t1 <- sample(seq_along(W)[W==1],ns, replace = replace)
q_pred_t <- c(q_pred_t, c(p1[inds_t0],p1[inds_t1]))
q_pred_c <- c(q_pred_c, c(p0[inds_t0],p0[inds_t1]))
q_resp <- c(q_resp, c(Y[inds_t0],Y[inds_t1]))
q_treat <- c(q_treat, c(W[inds_t0],W[inds_t1]))
q_treat_label <- c(q_treat_label, c(W_label[inds_t0],W_label[inds_t1]))
q_iter <- c(q_iter, c(rep(i,ns),rep(i,ns)))
}
}
else {
for(i in c(1:n_bs)){
print(paste0("boostrap iter: ", i))
# subsample must be defined for a particular model
# it must append to the above q_ variables in the calling environment via <<-
inds <- sample(length(p1), ns, replace = replace)
q_pred_t <- c(q_pred_t, p1[inds])
q_pred_c <- c(q_pred_c, p0[inds])
q_resp <- c(q_resp, Y[inds])
q_treat <- c(q_treat, W[inds])
q_treat_label <- c(q_treat_label, W_label[inds])
q_iter <- c(q_iter, rep(i,ns))
}
}
dif.pred <- q_pred_t - q_pred_c
if(all(c(0,1) %in% unique(q_treat))){
q_treat <- 2*q_treat-1
}
mm <- cbind(dif.pred = dif.pred, y = q_resp, ct = q_treat, ctl = q_treat_label, dif.pred_r = rank(-dif.pred), i = q_iter)
stopifnot(all(c(-1,1) %in% unique(q_treat)))
# Cumulatively sum the outcome by treatment and control groups
mmo <- mm[order(-dif.pred)[],]
mmo <- cbind(mmo, cdr = cumsum(mmo[,'y']*mmo[,'ct']))
# show cumsum(dr) for individual bootstrap iterations
mmo_df <- as.data.frame(mmo)
mmo_df <- mmo_df %>%
dplyr::group_by(i) %>%
dplyr::arrange(-dif.pred) %>% dplyr::mutate(cdri = cumsum(y*ct))
# Plot mean with min/max error bars, quantizing scoring (q = 10^x)
q <- 1/x_interval
mmo_dfs <- mmo_df %>% dplyr::group_by(dif.pred = floor(dif.pred*q)/q) %>%
dplyr::summarize(min_cdri = min(~cdri),
sd_cdri = sd(~cdri),
max_cdri = max(~cdri),
mean_cdri = mean(~cdri))
mmo_dfs <- cbind(mmo_dfs, group=rev(seq_along(mmo_dfs$mean_cdri))) # note: group is reversed
mmo_dfs$sd_cdri[is.na(mmo_dfs$sd_cdri)] <- 0
max_mean_uplift <- max(mmo_dfs$mean_cdri)
max_mean_uplift
max_group <- min(mmo_dfs$group[mmo_dfs$mean_cdri==max_mean_uplift])
max_group
dr_opt_min <- min(mmo_dfs$dif.pred[mmo_dfs$group<=max_group])
dr_opt_min
dr_opt_max <- max(mmo_dfs$dif.pred[mmo_dfs$group<=max_group])
dr_opt_max
mean_total_response_tc <- sum(mmo_df$y[mmo_df$ct==-1])/n_bs
mean_total_response_tc
diff_uplift_pct <- 100 * max_mean_uplift / mean_total_response_tc
diff_uplift_pct
mean_opt_users_targeted <- length(mmo_df$y[mmo_df$dif.pred>=dr_opt_min & mmo_df$ct==-1])/n_bs
mean_opt_users_targeted
mean_total_sampled_users <- length(mmo_df$y[mmo_df$ct==-1])/n_bs
mean_total_sampled_users
if(max_mean_uplift == 0){
dr_opt_min <- dr_opt_max
opt_users_targeted <- 0
}
config <- list(
ct=0,
tt=1,
model_type="cf"
)
wr <- function(s,c){
whisker::whisker.render(s,c)
}
s <- sign(mean_total_response_tc)
p1 <- ggplot(mmo_dfs, aes(x = dif.pred, y = ~mean_cdri/mean_total_response_tc*s)) +
geom_point(size = 2) +
#geom_errorbar(aes(ymin = min_cdri, ymax = max_cdri)) +
geom_errorbar(aes(ymin = (~mean_cdri-~sd_cdri)/mean_total_response_tc*s, ymax = (~mean_cdri+~sd_cdri)/mean_total_response_tc*s)) +
scale_x_reverse() +
xlab("score") +
ylab("CDR") +
labs(
title=wr("Cumulative Differential Response T{{{tt}}}-T{{{ct}}}\n  model_type: {{{model_type}}}; {{{n_bs}}} subsample iterations of size {{{mean_total_sampled_users}}}\n  max mean uplift: {{{diff_uplift_pct}}}% of T{{{ct}}} result\n  optimum: {{{opt_pct_users_targeted}}}% of subjects scoring: [{{{dr_opt_min}}},{{{dr_opt_max}}}]; uplift/subject: {{{uplift_per_subject}}}", list(tt=config$tt, ct=config$ct, model_type=config$model_type, n_bs=n_bs, max_mean_uplift=round(max_mean_uplift,2), diff_uplift_pct=round(diff_uplift_pct,2), mean_opt_users_targeted=round(mean_opt_users_targeted,0), mean_total_sampled_users = mean_total_sampled_users, opt_pct_users_targeted = round(100*mean_opt_users_targeted/mean_total_sampled_users,3), dr_opt_min=round(dr_opt_min,3), dr_opt_max=round(dr_opt_max,3), uplift_per_subject = round(max_mean_uplift/mean_opt_users_targeted,3)))
) +
theme(plot.title = element_text(size=8))
p2 <- ggplot(data.frame(score=mmo_df$dif.pred, treatment=as.factor(mmo_df$ctl)), aes(x=~score, fill=~treatment)) +
geom_histogram(position="dodge", bins = 100, linetype="blank") +
scale_x_reverse() +
theme(legend.position = c(0.9, 0.8))
gridExtra::grid.arrange(p1, p2, nrow=2)
}
plot_uplift(tau.hat$predictions, W.test, Y.test)
library(dplyr)
plot_uplift(tau.hat$predictions, W.test, Y.test)
#' Creates an uplift plot of cumulative differential treatment/control outcomes
#' versus model score.  Also provides a selection of metrics: max uplift as pct
#' of total control outcome, optimum users targeted and optimum score targeting
#' range.
#'
#' @param p1 numeric vector of uplift predictions; can also be predicted outcomes
#'   for treated case (in this case p0 should contain predicted outcomes for
#'   the control case)
#' @param W binary vector {1,0} of treatment assignments
#' @param Y numeric vector of responses
#' @param ns integer number of samples per bootstrap iteration; default min(table(W))
#' @param n_bs integer number of bootstrap iterations
#' @param W_label optional labels for the treatment options (default W)
#' @param p0 optional numeric vector of predicted outcomes for control case
#' @param balanced optional boolean whether to sample equal proportions from
#'   treatment and control cases; default TRUE
#' @param replace optional boolean whether to use replacement when sampling;
#'   default TRUE
#' @param x_interval optional numeric the interval with which to split the
#' @param ... additional arguments (unused)
#'   x-axis
#'
#' @import ggplot2 graphics
#' @importFrom dplyr %>%
#'
#' @examples \dontrun{
#'
#' set.seed(123)
#'
#' rl <- function(x){
#'   round(1/(1+exp(-x)))
#' }
#' n = 2000; p = 10
#' X = matrix(rnorm(n*p), n, p)
#' W = rbinom(n, 1, 0.2)
#' Y = rl(rl(X[,1]) * W - rl(X[,3]) * W + rnorm(n))
#' tau.forest = causal_forest(X, Y, W)
#' tau.hat = predict(tau.forest, X)
#' plot_uplift(tau.hat$predictions, W, Y, n_bs=20, x_interval = 0.05, balanced = FALSE)
#' plot_uplift(tau.hat$predictions, W, Y, n_bs=20, x_interval = 0.05, balanced = TRUE)
#'
#' }
#' @export
plot_uplift <- function(p1,
W,
Y,
ns=min(table(W)),
n_bs = 1,
W_label=W,
p0=rep(0,length(p1)),
balanced = TRUE,
replace = TRUE,
x_interval = 0.1,
...
){
q_pred_t <- c()
q_pred_c <- c()
q_resp <- c()
q_treat <- c()
q_treat_label <- c()
q_iter <- c()
if(balanced){
for(i in c(1:n_bs)){
inds_t0 <- sample(seq_along(W)[W==0],ns, replace = replace)
inds_t1 <- sample(seq_along(W)[W==1],ns, replace = replace)
q_pred_t <- c(q_pred_t, c(p1[inds_t0],p1[inds_t1]))
q_pred_c <- c(q_pred_c, c(p0[inds_t0],p0[inds_t1]))
q_resp <- c(q_resp, c(Y[inds_t0],Y[inds_t1]))
q_treat <- c(q_treat, c(W[inds_t0],W[inds_t1]))
q_treat_label <- c(q_treat_label, c(W_label[inds_t0],W_label[inds_t1]))
q_iter <- c(q_iter, c(rep(i,ns),rep(i,ns)))
}
}
else {
for(i in c(1:n_bs)){
print(paste0("boostrap iter: ", i))
# subsample must be defined for a particular model
# it must append to the above q_ variables in the calling environment via <<-
inds <- sample(length(p1), ns, replace = replace)
q_pred_t <- c(q_pred_t, p1[inds])
q_pred_c <- c(q_pred_c, p0[inds])
q_resp <- c(q_resp, Y[inds])
q_treat <- c(q_treat, W[inds])
q_treat_label <- c(q_treat_label, W_label[inds])
q_iter <- c(q_iter, rep(i,ns))
}
}
dif.pred <- q_pred_t - q_pred_c
if(all(c(0,1) %in% unique(q_treat))){
q_treat <- 2*q_treat-1
}
mm <- cbind(dif.pred = dif.pred, y = q_resp, ct = q_treat, ctl = q_treat_label, dif.pred_r = rank(-dif.pred), i = q_iter)
stopifnot(all(c(-1,1) %in% unique(q_treat)))
# Cumulatively sum the outcome by treatment and control groups
mmo <- mm[order(-dif.pred)[],]
mmo <- cbind(mmo, cdr = cumsum(mmo[,'y']*mmo[,'ct']))
# show cumsum(dr) for individual bootstrap iterations
mmo_df <- as.data.frame(mmo)
mmo_df <- mmo_df %>%
dplyr::group_by(i) %>%
dplyr::arrange(-dif.pred) %>% dplyr::mutate(cdri = cumsum(y*ct))
# Plot mean with min/max error bars, quantizing scoring (q = 10^x)
q <- 1/x_interval
mmo_dfs <- mmo_df %>% dplyr::group_by(dif.pred = floor(dif.pred*q)/q) %>%
dplyr::summarize(min_cdri = min(cdri),
sd_cdri = sd(cdri),
max_cdri = max(cdri),
mean_cdri = mean(cdri))
mmo_dfs <- cbind(mmo_dfs, group=rev(seq_along(mmo_dfs$mean_cdri))) # note: group is reversed
mmo_dfs$sd_cdri[is.na(mmo_dfs$sd_cdri)] <- 0
max_mean_uplift <- max(mmo_dfs$mean_cdri)
max_mean_uplift
max_group <- min(mmo_dfs$group[mmo_dfs$mean_cdri==max_mean_uplift])
max_group
dr_opt_min <- min(mmo_dfs$dif.pred[mmo_dfs$group<=max_group])
dr_opt_min
dr_opt_max <- max(mmo_dfs$dif.pred[mmo_dfs$group<=max_group])
dr_opt_max
mean_total_response_tc <- sum(mmo_df$y[mmo_df$ct==-1])/n_bs
mean_total_response_tc
diff_uplift_pct <- 100 * max_mean_uplift / mean_total_response_tc
diff_uplift_pct
mean_opt_users_targeted <- length(mmo_df$y[mmo_df$dif.pred>=dr_opt_min & mmo_df$ct==-1])/n_bs
mean_opt_users_targeted
mean_total_sampled_users <- length(mmo_df$y[mmo_df$ct==-1])/n_bs
mean_total_sampled_users
if(max_mean_uplift == 0){
dr_opt_min <- dr_opt_max
opt_users_targeted <- 0
}
config <- list(
ct=0,
tt=1,
model_type="cf"
)
wr <- function(s,c){
whisker::whisker.render(s,c)
}
s <- sign(mean_total_response_tc)
p1 <- ggplot(mmo_dfs, aes(x = dif.pred, y = mean_cdri/mean_total_response_tc*s)) +
geom_point(size = 2) +
#geom_errorbar(aes(ymin = min_cdri, ymax = max_cdri)) +
geom_errorbar(aes(ymin = (mean_cdri-sd_cdri)/mean_total_response_tc*s, ymax = (mean_cdri+sd_cdri)/mean_total_response_tc*s)) +
scale_x_reverse() +
xlab("score") +
ylab("CDR") +
labs(
title=wr("Cumulative Differential Response T{{{tt}}}-T{{{ct}}}\n  model_type: {{{model_type}}}; {{{n_bs}}} subsample iterations of size {{{mean_total_sampled_users}}}\n  max mean uplift: {{{diff_uplift_pct}}}% of T{{{ct}}} result\n  optimum: {{{opt_pct_users_targeted}}}% of subjects scoring: [{{{dr_opt_min}}},{{{dr_opt_max}}}]; uplift/subject: {{{uplift_per_subject}}}", list(tt=config$tt, ct=config$ct, model_type=config$model_type, n_bs=n_bs, max_mean_uplift=round(max_mean_uplift,2), diff_uplift_pct=round(diff_uplift_pct,2), mean_opt_users_targeted=round(mean_opt_users_targeted,0), mean_total_sampled_users = mean_total_sampled_users, opt_pct_users_targeted = round(100*mean_opt_users_targeted/mean_total_sampled_users,3), dr_opt_min=round(dr_opt_min,3), dr_opt_max=round(dr_opt_max,3), uplift_per_subject = round(max_mean_uplift/mean_opt_users_targeted,3)))
) +
theme(plot.title = element_text(size=8))
p2 <- ggplot(data.frame(score=mmo_df$dif.pred, treatment=as.factor(mmo_df$ctl)), aes(x=score, fill=treatment)) +
geom_histogram(position="dodge", bins = 100, linetype="blank") +
scale_x_reverse() +
theme(legend.position = c(0.9, 0.8))
gridExtra::grid.arrange(p1, p2, nrow=2)
}
plot_uplift(tau.hat$predictions, W.test, Y.test)
install.packages("qpdf")
library(qpdf)
Sys.which(Sys.getenv("R_QPDF", "qpdf"))
Sys.getenv("PATH")
devtools::release()
devtools::check_win_devel()
devtools::build_win()
