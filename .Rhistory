res_bf <- c(res_bf, r)
}
# Holm: adjust the p-values and reject/accept
holm_reject <- p.adjust(sort(p_values), "holm") <= alpha
for(r in holm_reject){
res_holm <- c(res_holm, r)
}
}
library(pwr)
library(ggplot2)
set.seed(1)
mde <- 0.1  # minimum detectable effect
cr_a <- 0.25 # the expected conversion rate for group A
alpha <- 0.05 # the false positive rate
power <- 0.80 # 1-false negative rate
ptpt <- pwr.2p.test(h = ES.h(p1 = cr_a, p2 = (1+mde)*cr_a),
sig.level = alpha,
power = power
)
n_obs <- ceiling(ptpt$n)
#
# monte carlo runs n_simulations and calls the callback function each time with the ... optional args
#
monte_carlo <- function(n_simulations, callback, ...){
simulations <- 1:n_simulations
sapply(1:n_simulations, function(x){
callback(...)
})
}
set.seed(1)
# make our "true" effect zero: the null hypothesis is always true
effect <- 0
cr_b <- (1+effect)*cr_a
observations <- 2*n_obs
reject_at_i <- function(observations, i){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
( prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value ) < alpha
}
# run the sim
rejected.H0 <- monte_carlo(1000,
callback=reject_at_i,
observations=n_obs,
i=n_obs
)
# output the rejection table
table(rejected.H0)
m<-2
1-(1-alpha)^m
set.seed(1)
n_tests_per_trial <- 2
n_trials <- 1000
rejects <- 0
for(i in 1:n_trials){
# run the sim
rejected.H0 <- monte_carlo(n_tests_per_trial,
callback=reject_at_i,
observations=n_obs,
i=n_obs
)
if(!is.na(table(rejected.H0)[2])) {
rejects <- rejects + n_tests_per_trial
}
}
rejects/(n_trials * n_tests_per_trial)
set.seed(1)
p_value_at_i <- function(observations, i){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
rejects <- 0
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni-adjust the p-values and reject any cases with p-values <= alpha
rejects <- rejects + sum(p_values*n_tests_per_trial <= alpha)
}
rejects/(n_trials * n_tests_per_trial)
set.seed(1)
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni: adjust the p-values and reject/accept
bf_reject <- p.adjust(p_values, "bonferroni") <= alpha
for(r in bf_reject){
res_bf <- c(res_bf, r)
}
# Holm: adjust the p-values and reject/accept
holm_reject <- p.adjust(sort(p_values), "holm") <= alpha
for(r in holm_reject){
res_holm <- c(res_holm, r)
}
}
sum(res_bf)/length(res_bf)
sum(res_holm)/length(res_holm)
set.seed(1)
p_value_at_i <- function(observations, i){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
rejects <- 0
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni-adjust the p-values and reject any cases with p-values <= alpha
rejects <- rejects + sum(any(p_values*n_tests_per_trial <= alpha))
}
rejects/n_trials
set.seed(1)
n_tests_per_trial <- 2
n_trials <- 1000
rejects <- 0
for(i in 1:n_trials){
# run the sim
rejected.H0 <- monte_carlo(n_tests_per_trial,
callback=reject_at_i,
observations=n_obs,
i=n_obs
)
if(!is.na(table(rejected.H0)[2])) {
rejects <- rejects + 1
}
}
rejects/n_trials
set.seed(1)
p_value_at_i <- function(observations, i){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
rejects <- 0
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni-adjust the p-values and reject any cases with p-values <= alpha
rejects <- rejects + sum(any(p_values*n_tests_per_trial <= alpha))
}
rejects/n_trials
set.seed(2)
p_value_at_i <- function(observations, i){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
rejects <- 0
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni-adjust the p-values and reject any cases with p-values <= alpha
rejects <- rejects + sum(any(p_values*n_tests_per_trial <= alpha))
}
rejects/n_trials
set.seed(3)
p_value_at_i <- function(observations, i){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
rejects <- 0
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni-adjust the p-values and reject any cases with p-values <= alpha
rejects <- rejects + sum(any(p_values*n_tests_per_trial <= alpha))
}
rejects/n_trials
set.seed(1)
p_value_at_i <- function(observations, i){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
rejects <- 0
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni-adjust the p-values and reject any cases with p-values <= alpha
rejects <- rejects + sum(any(p_values*n_tests_per_trial <= alpha))
}
rejects/n_trials
set.seed(1)
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni: adjust the p-values and reject/accept
bf_reject <- p.adjust(p_values, "bonferroni") <= alpha
res_bf <- c(res_bf, sum(any(bf_reject)))
# Holm: adjust the p-values and reject/accept
holm_reject <- p.adjust(sort(p_values), "holm") <= alpha
res_holm <- c(res_holm, sum(any(holm_reject)))
}
# Calculate
sum(res_bf)/length(res_bf)
sum(res_holm)/length(res_holm)
set.seed(1)
p_value_at_i <- function(observations, i, cr_a, cr_b){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
null_true <- rbinom(1,1,prob = 0.5)
effect <- mde * null_true
cr_b <- (1+effect)*cr_a
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs,
cr_a=cr_a,
cr_b=cr_b
)
# Bonferroni: adjust the p-values and reject/accept
reject_bf <- p.adjust(p_values, "bonferroni") <= alpha
res_bf <- rbind(res_bf, c(sum(any(reject_bf)), null_true))
# Holm: adjust the p-values and reject/accept
reject_holm <- p.adjust(sort(p_values), "holm") <= alpha
res_holm <- rbind(res_holm, c(sum(any(reject_hold)), null_true))
}
set.seed(1)
p_value_at_i <- function(observations, i, cr_a, cr_b){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
null_true <- rbinom(1,1,prob = 0.5)
effect <- mde * null_true
cr_b <- (1+effect)*cr_a
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs,
cr_a=cr_a,
cr_b=cr_b
)
# Bonferroni: adjust the p-values and reject/accept
reject_bf <- p.adjust(p_values, "bonferroni") <= alpha
res_bf <- rbind(res_bf, c(sum(any(reject_bf)), null_true))
# Holm: adjust the p-values and reject/accept
reject_holm <- p.adjust(sort(p_values), "holm") <= alpha
res_holm <- rbind(res_holm, c(sum(any(reject_holm)), null_true))
}
# the rows of the table represent the test result
# while the columns represent the null truth
table_bf <- table(Test=res_bf[,1], Null=res_bf[,2])
table_holm <- table(Test=res_holm[,1], Null=res_holm[,2])
# False positive rate
fpr_bf <- table_bf['1','0']/sum(table_bf[,'0'])
fpr_holm <- table_holm['1','0']/sum(table_holm[,'0'])
print(paste0("FPR Bonferroni: ", round(fpr_bf,3), " FPR Holm: ", round(fpr_holm,3)))
# Power
power_bf <- table_bf['1','1']/sum(table_bf[,'1'])
power_holm <- table_holm['1','1']/sum(table_holm[,'1'])
print(paste0("Power Bonferroni: ", round(power_bf,3), " Power Holm: ", round(power_holm,3)))
# Comparing the Power of Holm vs. Bonferroni
print(paste0("Power Holm/Power Bonferroni: ", round(power_holm/power_bf,3)))
table_bf
table_holm
set.seed(1)
p_value_at_i <- function(observations, i, cr_a, cr_b){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
null_true <- rbinom(1,1,prob = 0.5)
effect <- mde * null_true
cr_b <- (1+effect)*cr_a
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs,
cr_a=cr_a,
cr_b=cr_b
)
# Bonferroni: adjust the p-values and reject/accept
reject_bf <- p.adjust(p_values, "bonferroni") <= alpha
for(r in reject_bf){
res_bf <- rbind(res_bf, c(r, null_true))
}
# Holm: adjust the p-values and reject/accept
reject_holm <- p.adjust(sort(p_values), "holm") <= alpha
for(r in reject_holm){
res_holm <- rbind(res_holm, c(r, null_true))
}
}
# the rows of the table represent the test result
# while the columns represent the null truth
table_bf <- table(Test=res_bf[,1], Null=res_bf[,2])
table_holm <- table(Test=res_holm[,1], Null=res_holm[,2])
# False positive rate
fpr_bf <- table_bf['1','0']/sum(table_bf[,'0'])
fpr_holm <- table_holm['1','0']/sum(table_holm[,'0'])
print(paste0("FPR Bonferroni: ", round(fpr_bf,3), " FPR Holm: ", round(fpr_holm,3)))
# Power
power_bf <- table_bf['1','1']/sum(table_bf[,'1'])
power_holm <- table_holm['1','1']/sum(table_holm[,'1'])
print(paste0("Power Bonferroni: ", round(power_bf,3), " Power Holm: ", round(power_holm,3)))
# Comparing the Power of Holm vs. Bonferroni
print(paste0("Power Holm/Power Bonferroni: ", round(power_holm/power_bf,3)))
table_bf
table_holm
set.seed(1)
p_value_at_i <- function(observations, i, cr_a, cr_b){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
null_true <- rbinom(1,1,prob = 0.5)
effect <- mde * null_true
cr_b <- (1+effect)*cr_a
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs,
cr_a=cr_a,
cr_b=cr_b
)
# Bonferroni: adjust the p-values and reject/accept
reject_bf <- p.adjust(p_values, "bonferroni") <= alpha
for(r in reject_bf){
res_bf <- rbind(res_bf, c(r, null_true))
}
# Holm: adjust the p-values and reject/accept
reject_holm <- p.adjust(sort(p_values), "holm") <= alpha
for(r in reject_holm){
res_holm <- rbind(res_holm, c(r, null_true))
}
}
# the rows of the table represent the test result
# while the columns represent the null truth
table_bf <- table(Test=res_bf[,1], Null=res_bf[,2])
table_holm <- table(Test=res_holm[,1], Null=res_holm[,2])
# False positive rate
fpr_bf <- table_bf['1','0']/sum(table_bf[,'0'])
fpr_holm <- table_holm['1','0']/sum(table_holm[,'0'])
print(paste0("FPR Bonferroni: ", round(fpr_bf,3), " FPR Holm: ", round(fpr_holm,3)))
# Power
power_bf <- table_bf['1','1']/sum(table_bf[,'1'])
power_holm <- table_holm['1','1']/sum(table_holm[,'1'])
print(paste0("Power Bonferroni: ", round(power_bf,3), " Power Holm: ", round(power_holm,3)))
# Comparing the Power of Holm vs. Bonferroni
print(paste0("Power Holm/Power Bonferroni: ", round(power_holm/power_bf,3)))
set.seed(1)
p_value_at_i <- function(observations, i){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
rejects <- 0
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni-adjust the p-values and reject any cases with p-values <= alpha
rejects <- rejects + any(p_values*n_tests_per_trial <= alpha)
}
# Calculate FWER
rejects/n_trials
any(TRUE, FALSE, FALSE)
sum(any(TRUE, FALSE, FALSE))
any(TRUE, TRUE)
set.seed(1)
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni: adjust the p-values and reject/accept
bf_reject <- p.adjust(p_values, "bonferroni") <= alpha
res_bf <- c(res_bf, sum(any(bf_reject)))
# Holm: adjust the p-values and reject/accept
holm_reject <- p.adjust(sort(p_values), "holm") <= alpha
res_holm <- c(res_holm, sum(any(holm_reject)))
}
# Calculate FWER
sum(res_bf)/length(res_bf)
sum(res_holm)/length(res_holm)
table_bf
set.seed(1)
p_value_at_i <- function(observations, i, cr_a, cr_b){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
null_true <- rbinom(1,1,prob = 0.5)
effect <- mde * null_true
cr_b <- (1+effect)*cr_a
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs,
cr_a=cr_a,
cr_b=cr_b
)
# Bonferroni: adjust the p-values and reject/accept
reject_bf <- p.adjust(p_values, "bonferroni") <= alpha
for(r in reject_bf){
res_bf <- rbind(res_bf, c(r, null_true))
}
# Holm: adjust the p-values and reject/accept
reject_holm <- p.adjust(sort(p_values), "holm") <= alpha
for(r in reject_holm){
res_holm <- rbind(res_holm, c(r, null_true))
}
}
# the rows of the table represent the test result
# while the columns represent the null truth
table_bf <- table(Test=res_bf[,1], Null=res_bf[,2])
table_holm <- table(Test=res_holm[,1], Null=res_holm[,2])
# False positive rate
fpr_bf <- table_bf['1','0']/sum(table_bf[,'0'])
fpr_holm <- table_holm['1','0']/sum(table_holm[,'0'])
print(paste0("FPR Bonferroni: ", round(fpr_bf,3), " FPR Holm: ", round(fpr_holm,3)))
# Power
power_bf <- table_bf['1','1']/sum(table_bf[,'1'])
power_holm <- table_holm['1','1']/sum(table_holm[,'1'])
print(paste0("Power Bonferroni: ", round(power_bf,3), " Power Holm: ", round(power_holm,3)))
# Comparing the Power of Holm vs. Bonferroni
print(paste0("Power Holm/Power Bonferroni: ", round(power_holm/power_bf,3)))
