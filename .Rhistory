set.seed(1)
p_value_at_i <- function(observations, i){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
rejects <- 0
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni-adjust the p-values and reject any cases with p-values <= alpha
rejects <- rejects + sum(any(p_values*n_tests_per_trial <= alpha))
}
rejects/n_trials
set.seed(1)
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni: adjust the p-values and reject/accept
bf_reject <- p.adjust(p_values, "bonferroni") <= alpha
res_bf <- c(res_bf, sum(any(bf_reject)))
# Holm: adjust the p-values and reject/accept
holm_reject <- p.adjust(sort(p_values), "holm") <= alpha
res_holm <- c(res_holm, sum(any(holm_reject)))
}
# Calculate
sum(res_bf)/length(res_bf)
sum(res_holm)/length(res_holm)
set.seed(1)
p_value_at_i <- function(observations, i, cr_a, cr_b){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
null_true <- rbinom(1,1,prob = 0.5)
effect <- mde * null_true
cr_b <- (1+effect)*cr_a
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs,
cr_a=cr_a,
cr_b=cr_b
)
# Bonferroni: adjust the p-values and reject/accept
reject_bf <- p.adjust(p_values, "bonferroni") <= alpha
res_bf <- rbind(res_bf, c(sum(any(reject_bf)), null_true))
# Holm: adjust the p-values and reject/accept
reject_holm <- p.adjust(sort(p_values), "holm") <= alpha
res_holm <- rbind(res_holm, c(sum(any(reject_hold)), null_true))
}
set.seed(1)
p_value_at_i <- function(observations, i, cr_a, cr_b){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
null_true <- rbinom(1,1,prob = 0.5)
effect <- mde * null_true
cr_b <- (1+effect)*cr_a
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs,
cr_a=cr_a,
cr_b=cr_b
)
# Bonferroni: adjust the p-values and reject/accept
reject_bf <- p.adjust(p_values, "bonferroni") <= alpha
res_bf <- rbind(res_bf, c(sum(any(reject_bf)), null_true))
# Holm: adjust the p-values and reject/accept
reject_holm <- p.adjust(sort(p_values), "holm") <= alpha
res_holm <- rbind(res_holm, c(sum(any(reject_holm)), null_true))
}
# the rows of the table represent the test result
# while the columns represent the null truth
table_bf <- table(Test=res_bf[,1], Null=res_bf[,2])
table_holm <- table(Test=res_holm[,1], Null=res_holm[,2])
# False positive rate
fpr_bf <- table_bf['1','0']/sum(table_bf[,'0'])
fpr_holm <- table_holm['1','0']/sum(table_holm[,'0'])
print(paste0("FPR Bonferroni: ", round(fpr_bf,3), " FPR Holm: ", round(fpr_holm,3)))
# Power
power_bf <- table_bf['1','1']/sum(table_bf[,'1'])
power_holm <- table_holm['1','1']/sum(table_holm[,'1'])
print(paste0("Power Bonferroni: ", round(power_bf,3), " Power Holm: ", round(power_holm,3)))
# Comparing the Power of Holm vs. Bonferroni
print(paste0("Power Holm/Power Bonferroni: ", round(power_holm/power_bf,3)))
table_bf
table_holm
set.seed(1)
p_value_at_i <- function(observations, i, cr_a, cr_b){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
null_true <- rbinom(1,1,prob = 0.5)
effect <- mde * null_true
cr_b <- (1+effect)*cr_a
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs,
cr_a=cr_a,
cr_b=cr_b
)
# Bonferroni: adjust the p-values and reject/accept
reject_bf <- p.adjust(p_values, "bonferroni") <= alpha
for(r in reject_bf){
res_bf <- rbind(res_bf, c(r, null_true))
}
# Holm: adjust the p-values and reject/accept
reject_holm <- p.adjust(sort(p_values), "holm") <= alpha
for(r in reject_holm){
res_holm <- rbind(res_holm, c(r, null_true))
}
}
# the rows of the table represent the test result
# while the columns represent the null truth
table_bf <- table(Test=res_bf[,1], Null=res_bf[,2])
table_holm <- table(Test=res_holm[,1], Null=res_holm[,2])
# False positive rate
fpr_bf <- table_bf['1','0']/sum(table_bf[,'0'])
fpr_holm <- table_holm['1','0']/sum(table_holm[,'0'])
print(paste0("FPR Bonferroni: ", round(fpr_bf,3), " FPR Holm: ", round(fpr_holm,3)))
# Power
power_bf <- table_bf['1','1']/sum(table_bf[,'1'])
power_holm <- table_holm['1','1']/sum(table_holm[,'1'])
print(paste0("Power Bonferroni: ", round(power_bf,3), " Power Holm: ", round(power_holm,3)))
# Comparing the Power of Holm vs. Bonferroni
print(paste0("Power Holm/Power Bonferroni: ", round(power_holm/power_bf,3)))
table_bf
table_holm
set.seed(1)
p_value_at_i <- function(observations, i, cr_a, cr_b){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
null_true <- rbinom(1,1,prob = 0.5)
effect <- mde * null_true
cr_b <- (1+effect)*cr_a
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs,
cr_a=cr_a,
cr_b=cr_b
)
# Bonferroni: adjust the p-values and reject/accept
reject_bf <- p.adjust(p_values, "bonferroni") <= alpha
for(r in reject_bf){
res_bf <- rbind(res_bf, c(r, null_true))
}
# Holm: adjust the p-values and reject/accept
reject_holm <- p.adjust(sort(p_values), "holm") <= alpha
for(r in reject_holm){
res_holm <- rbind(res_holm, c(r, null_true))
}
}
# the rows of the table represent the test result
# while the columns represent the null truth
table_bf <- table(Test=res_bf[,1], Null=res_bf[,2])
table_holm <- table(Test=res_holm[,1], Null=res_holm[,2])
# False positive rate
fpr_bf <- table_bf['1','0']/sum(table_bf[,'0'])
fpr_holm <- table_holm['1','0']/sum(table_holm[,'0'])
print(paste0("FPR Bonferroni: ", round(fpr_bf,3), " FPR Holm: ", round(fpr_holm,3)))
# Power
power_bf <- table_bf['1','1']/sum(table_bf[,'1'])
power_holm <- table_holm['1','1']/sum(table_holm[,'1'])
print(paste0("Power Bonferroni: ", round(power_bf,3), " Power Holm: ", round(power_holm,3)))
# Comparing the Power of Holm vs. Bonferroni
print(paste0("Power Holm/Power Bonferroni: ", round(power_holm/power_bf,3)))
set.seed(1)
p_value_at_i <- function(observations, i){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
rejects <- 0
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni-adjust the p-values and reject any cases with p-values <= alpha
rejects <- rejects + any(p_values*n_tests_per_trial <= alpha)
}
# Calculate FWER
rejects/n_trials
any(TRUE, FALSE, FALSE)
sum(any(TRUE, FALSE, FALSE))
any(TRUE, TRUE)
set.seed(1)
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs
)
# Bonferroni: adjust the p-values and reject/accept
bf_reject <- p.adjust(p_values, "bonferroni") <= alpha
res_bf <- c(res_bf, sum(any(bf_reject)))
# Holm: adjust the p-values and reject/accept
holm_reject <- p.adjust(sort(p_values), "holm") <= alpha
res_holm <- c(res_holm, sum(any(holm_reject)))
}
# Calculate FWER
sum(res_bf)/length(res_bf)
sum(res_holm)/length(res_holm)
table_bf
set.seed(1)
p_value_at_i <- function(observations, i, cr_a, cr_b){
conversions_a <- rbinom(observations, 1, cr_a)
conversions_b <- rbinom(observations, 1, cr_b)
prop.test(c(sum(conversions_a[1:i]),sum(conversions_b[1:i])), c(i,i))$p.value
}
n_tests_per_trial <- 2
n_trials <- 1000
res_bf <- c()
res_holm <- c()
for(i in 1:n_trials){
null_true <- rbinom(1,1,prob = 0.5)
effect <- mde * null_true
cr_b <- (1+effect)*cr_a
# run n_tests_per_trial
p_values <- monte_carlo(n_tests_per_trial,
callback=p_value_at_i,
observations=n_obs,
i=n_obs,
cr_a=cr_a,
cr_b=cr_b
)
# Bonferroni: adjust the p-values and reject/accept
reject_bf <- p.adjust(p_values, "bonferroni") <= alpha
for(r in reject_bf){
res_bf <- rbind(res_bf, c(r, null_true))
}
# Holm: adjust the p-values and reject/accept
reject_holm <- p.adjust(sort(p_values), "holm") <= alpha
for(r in reject_holm){
res_holm <- rbind(res_holm, c(r, null_true))
}
}
# the rows of the table represent the test result
# while the columns represent the null truth
table_bf <- table(Test=res_bf[,1], Null=res_bf[,2])
table_holm <- table(Test=res_holm[,1], Null=res_holm[,2])
# False positive rate
fpr_bf <- table_bf['1','0']/sum(table_bf[,'0'])
fpr_holm <- table_holm['1','0']/sum(table_holm[,'0'])
print(paste0("FPR Bonferroni: ", round(fpr_bf,3), " FPR Holm: ", round(fpr_holm,3)))
# Power
power_bf <- table_bf['1','1']/sum(table_bf[,'1'])
power_holm <- table_holm['1','1']/sum(table_holm[,'1'])
print(paste0("Power Bonferroni: ", round(power_bf,3), " Power Holm: ", round(power_holm,3)))
# Comparing the Power of Holm vs. Bonferroni
print(paste0("Power Holm/Power Bonferroni: ", round(power_holm/power_bf,3)))
set.seed(1)
# the number of samples
n <- 1000
# uniform random on (-1,1)
x1 <- 2*runif(n)-1
x2 <- 2*runif(n)-1
x <- cbind(1, x1, x2)
# our betas
beta <- c(-1, -3.0, 5.0)
probs <- exp(beta %*% t(x))/(1+exp(beta %*% t(x)))
y <- rbinom(n,1,probs)
sim <- data.frame(id = seq(1:n), y = y, x1 = x1, x2 = x2)
mylogit <- glm(y ~ x1 + x2, data = sim, family = "binomial")
summary(mylogit)
mylogit$coefficients
library(bigrquery)
library(whisker)
library(condusco)
config <- list(
project = 'condusco-dev-002',
dataset = 'rstevenson',
table_prefix = 'indb_logreg_001'
)
wr <- function(s){whisker.render(s,config)}
# put the simulated data in GCP
insert_upload_job(
project = wr('{{{project}}}'),
dataset = wr('{{{dataset}}}'),
table = "logreg_sim",
values = sim,
write_disposition = "WRITE_TRUNCATE"
)
library(bigrquery)
library(whisker)
library(condusco)
config <- list(
project = 'condusco-dev-002',
dataset = 'rstevenson',
table_prefix = 'indb_logreg_001'
)
wr <- function(s){whisker.render(s,config)}
# put the simulated data in GCP
insert_upload_job(
project = wr('{{{project}}}'),
dataset = wr('{{{dataset}}}'),
table = "logreg_sim",
values = sim,
write_disposition = "WRITE_TRUNCATE"
)
library(bigrquery)
library(whisker)
library(condusco)
config <- list(
project = 'condusco-dev-002',
dataset = 'rstevenson',
table_prefix = 'indb_logreg_001'
)
wr <- function(s){whisker.render(s,config)}
# put the simulated data in GCP
insert_upload_job(
project = wr('{{{project}}}'),
dataset = wr('{{{dataset}}}'),
table = "logreg_sim",
values = sim,
write_disposition = "WRITE_TRUNCATE"
)
query <- "
SELECT *
FROM {{{dataset}}}.{{{table_prefix}}}_model_params
;"
res <- query_exec(
whisker.render(query, params),
whisker.render('{{{project}}}', params),
use_legacy_sql = FALSE
)
query <- "
SELECT *
FROM {{{dataset}}}.{{{table_prefix}}}_model_params
;"
res <- query_exec(
wr(query),
wr('{{{project}}}'),
use_legacy_sql = FALSE
)
query <- "
SELECT *
FROM {{{dataset}}}.{{{table_prefix}}}_model_params
;"
query_exec(
wr(query),
wr('{{{project}}}'),
use_legacy_sql = FALSE
)
#
# Pipeline: predict
#
log_reg_predict <- function(params){
print ("log_reg_predict")
query <- '
SELECT
1/(1+exp(-1.0*(CONSTANT + {{#list}}a.{{val}}*b.{{val}} + {{/list}} + 0))) as probability
FROM {{{dataset}}}.{{{table_prefix}}}_model_params a
CROSS JOIN {{{data_table}}} b
ORDER BY {{{id_column}}}
'
res <- query_exec(
whisker.render(query, params),
whisker.render('{{{project}}}', params),
use_legacy_sql = FALSE
)
}
# Run the prediction pipeline with the following params
invocation_query <- '
SELECT
"{{{project}}}" as project,
"{{{dataset}}}" as dataset,
"{{{table_prefix}}}" as table_prefix,
"{{{dataset}}}.logreg_sim" as data_table,
"id" as id_column,
CONCAT("[", STRING_AGG(CONCAT("{\\"val\\": \\"",TRIM(fieldname), "\\"}")), "]") AS list
FROM {{{dataset}}}.{{{table_prefix}}}_fieldnames
'
predictions <- run_pipeline_gbq(
log_reg_predict,
whisker.render(invocation_query, config),
project = whisker.render('{{{project}}}', config),
use_legacy_sql = FALSE
)
round(predictions[[1]]$probability) == y
sum(round(predictions[[1]]$probability) == y)
# round(predictions[[1]]$probability) == y
sum(round(predictions[[1]]$probability) == y)
getwd()
rmarkdown::render("content/post/2019-11-05-in-database-logistic-regression-with-r.Rmd")
rmarkdown::render("content/post/2019-11-05-in-database-logistic-regression-with-r.Rmd")
rmarkdown::render("content/post/2019-11-05-in-database-logistic-regression-with-r.Rmd")
library(bigrquery)
library(whisker)
library(condusco)
# Uncomment and define your own config
# config <- list(
#   project = '<YOUR GBQ PROJECT>',
#   dataset = '<YOUR GBQ DATASET>',
#   table_prefix = '<A TABLE_PREFIX TO USE>'
# )
wr <- function(s, params=config){whisker.render(s,config)}
# put the simulated data in GCP
insert_upload_job(
project = wr('{{{project}}}'),
dataset = wr('{{{dataset}}}'),
table = "logreg_sim",
values = sim,
write_disposition = "WRITE_TRUNCATE"
)
# Run the prediction pipeline with the following params
invocation_query <- '
SELECT
"{{{project}}}" as project,
"{{{dataset}}}" as dataset,
"{{{table_prefix}}}" as table_prefix,
"{{{dataset}}}.logreg_sim" as data_table,
"id" as id_column,
CONCAT("[", STRING_AGG(CONCAT("{\\"val\\": \\"",TRIM(fieldname), "\\"}")), "]") AS list
FROM {{{dataset}}}.{{{table_prefix}}}_fieldnames
'
predictions <- run_pipeline_gbq(
log_reg_predict,
wr(invocation_query, config),
project = wr('{{{project}}}', config),
use_legacy_sql = FALSE
)
sum(round(predictions[[1]]$probability) == y)
# Run the prediction pipeline with the following params
invocation_query <- '
SELECT
"{{{project}}}" as project,
"{{{dataset}}}" as dataset,
"{{{table_prefix}}}" as table_prefix,
"{{{dataset}}}.logreg_sim" as data_table,
"id" as id_column,
CONCAT("[", STRING_AGG(CONCAT("{\\"val\\": \\"",TRIM(fieldname), "\\"}")), "]") AS list
FROM {{{dataset}}}.{{{table_prefix}}}_fieldnames
'
predictions <- run_pipeline_gbq(
log_reg_predict,
wr(invocation_query, config),
project = wr('{{{project}}}', config),
use_legacy_sql = FALSE
)
rmarkdown::render("content/post/2019-11-05-in-database-logistic-regression-with-r.Rmd")
rmarkdown::render("content/post/2019-11-05-in-database-logistic-regression-with-r.Rmd")
rmarkdown::render("content/post/2019-11-05-in-database-logistic-regression-with-r.Rmd")
config
blogdown:::insert_image_addin()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
2
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown::serve_site()
blogdown::serve_site()
blogdown:::insert_image_addin()
blogdown::serve_site()
