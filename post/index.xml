<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Roland&#39;s Blog</title>
    <link>/post.html</link>
    <description>Recent content in Posts on Roland&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 19 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Keeping Credentials Secret with Keyrings in R</title>
      <link>/2019/01/19/keeping-credentials-secret-with-keyrings-in-r.html</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/19/keeping-credentials-secret-with-keyrings-in-r.html</guid>
      <description>edit
Keeping credentials secret When accessing an API or database in R, it is often necessary to provide credentials such as login name and password.
Figure: Providing credentials via an interactive prompt
 Often it is also more convenient to provide credentials programatically in an R script, but best practices1 state:
 As with every programming language, it is important to avoid publishing code with your credentials in plain text.</description>
    </item>
    
    <item>
      <title>Using a Fixed Version of R on Linux</title>
      <link>/2019/01/05/using-a-fixed-version-of-r-on-linux.html</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/05/using-a-fixed-version-of-r-on-linux.html</guid>
      <description>edit
 The below article refers to setting up R and RStudio Server on a cloud Linux instance in a way that ensures R project reproducibility and facilitates collaboration. Many possible workflows exist to accomplish this. One might call the below presentation an “opinionated” solution based on what we have found to work in a production environment. Importantly, all development is on an RStudio Server cloud Linux instance, ensuring that we only have to support one operating system.</description>
    </item>
    
    <item>
      <title>In-database xgboost Predictions with R</title>
      <link>/2018/10/18/in-database-xgboost-predictions-with-r.html</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/18/in-database-xgboost-predictions-with-r.html</guid>
      <description>edit
xgboost(docs) is a popular R package for classification and regression, and the model of choice in many winning Kaggle competitions. Moving xgboost into a large-scale production environment, however, can lead to challenges when attempting to calculate predictions (“scores”) for large datasets. We present a novel solution for calculating batch predictions without having to transfer features stored in a database to the machine where the model is located; instead we convert the model predictions into SQL commands and thereby transfer the scoring process to the database.</description>
    </item>
    
    <item>
      <title>Cost Effective Partitioning in BigQuery with R</title>
      <link>/2018/05/02/cost-effective-partitioning-in-bigquery-with-r.html</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/02/cost-effective-partitioning-in-bigquery-with-r.html</guid>
      <description>edit
Introduction Companies using Google BigQuery for production analytics often run into the following problem: the company has a large user hit table that spans many years. Since queries are billed based on the fields accessed, and not on the date-ranges queried, queries on the table are billed for all available days and are increasingly wasteful.
Partitioning Tables
 A solution is to partition the table by date, so that users can query a particular range of dates; saving costs and decreasing query duration.</description>
    </item>
    
  </channel>
</rss>